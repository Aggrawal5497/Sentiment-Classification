{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "\n",
    "The Notebook presents a simple sentiment classification system using Keras LSTM network.\n",
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import helper\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data and creating pairs of sentence and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"imdb_labelled.txt\")\n",
    "data1 = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(\"amazon_cells_labelled.txt\")\n",
    "data2 = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(\"yelp_labelled.txt\")\n",
    "data3 = f.readlines()\n",
    "f.close()\n",
    "\n",
    "pairs = []\n",
    "for one in data1:\n",
    "    pairs.append(one.strip(\"\\n\").lower().split(\"\\t\"))\n",
    "    \n",
    "for one in data2:\n",
    "    pairs.append(one.strip(\"\\n\").lower().split(\"\\t\"))\n",
    "    \n",
    "for one in data3:\n",
    "    pairs.append(one.strip(\"\\n\").lower().split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"glove.6B.50d.txt\", encoding='utf-8')\n",
    "emb_dict = dict()\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coef = values[1:]\n",
    "    emb_dict[word] = coef\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = str.maketrans(\"\",\"\", string.punctuation)\n",
    "new_pairs = []\n",
    "for val in pairs:\n",
    "    sent = val[0]\n",
    "    sent = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-])\\s*\", r\"\\1 \", sent)\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('/', ' ')\n",
    "    sent = sent.translate(translation)\n",
    "    new_pairs.append([sent, val[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geting set of known words accordig to pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(['eos', 'pad'])\n",
    "for pair in new_pairs:\n",
    "    sent = pair[0]\n",
    "    for word in sent.split():\n",
    "        vocab.add(word) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "unk = -1\n",
    "unk_set = set()\n",
    "for word in vocab:\n",
    "    if emb_dict.get(word, -1) == -1:\n",
    "        unk += 1\n",
    "        unk_set.add(word)\n",
    "print(unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing unknown words with ```unk``` token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = []\n",
    "for pair in new_pairs:\n",
    "    sent = pair[0]\n",
    "    sent = sent.split()\n",
    "    for i, word in enumerate(sent):\n",
    "        if(word in unk_set):\n",
    "            sent[i] = \"unk\"\n",
    "    new_sent = ' '.join(sent)\n",
    "    n.append([new_sent, pair[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending ```eos``` token at end of sentencs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(['eos', 'pad'])\n",
    "for pair in n:\n",
    "    sent = pair[0]\n",
    "    for word in sent.split():\n",
    "        vocab.add(word)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating necessary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pad': 0}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = dict({'pad' : 0})\n",
    "print(word_to_index)\n",
    "for word in vocab:\n",
    "    if word != 'pad':\n",
    "        word_to_index[word] = len(word_to_index)\n",
    "\n",
    "index_to_word = dict(zip(word_to_index.values(), word_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_emb = np.zeros((len(word_to_index), 50))\n",
    "for word, index in word_to_index.items():\n",
    "    useful_emb[index] = emb_dict[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating indexed data and sentiment pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_pairs = []\n",
    "for pair in n:\n",
    "    sent = pair[0].split()\n",
    "    index_sent = []\n",
    "    for word in sent:\n",
    "        index_sent.append(word_to_index[word])\n",
    "    index_sent.append(word_to_index['eos'])\n",
    "    indexed_pairs.append([index_sent, ast.literal_eval(pair[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping important data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"important_data.obj\", \"wb\")\n",
    "pickle.dump([vocab, word_to_index, useful_emb], f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "del(emb_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(indexed_pairs) * 0.2)\n",
    "train_data = indexed_pairs[:-split_point]\n",
    "valid_data = indexed_pairs[-split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating batch generators for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = helper.batch_generator(train_data, 20)\n",
    "valid = helper.batch_generator(valid_data, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    m = Sequential()\n",
    "    m.add(Embedding(len(word_to_index),50,weights=[useful_emb], input_shape=[None,]))\n",
    "    m.add(LSTM(512, return_sequences = True))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(LSTM(512))\n",
    "    m.add(Dense(1, activation='sigmoid'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 50)          251500    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         1153024   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,504,237\n",
      "Trainable params: 3,504,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.7039 - acc: 0.5239Epoch 00000: saving model to model-00.hdf5\n",
      "120/120 [==============================] - 49s - loss: 0.7037 - acc: 0.5238 - val_loss: 0.7126 - val_acc: 0.4767\n",
      "Epoch 2/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6954 - acc: 0.4916Epoch 00001: saving model to model-01.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.6951 - acc: 0.4929 - val_loss: 0.7614 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6945 - acc: 0.5294Epoch 00002: saving model to model-02.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.6941 - acc: 0.5304 - val_loss: 0.7309 - val_acc: 0.4617\n",
      "Epoch 4/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6822 - acc: 0.5454Epoch 00003: saving model to model-03.hdf5\n",
      "120/120 [==============================] - 46s - loss: 0.6822 - acc: 0.5463 - val_loss: 0.7048 - val_acc: 0.4617\n",
      "Epoch 5/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6982 - acc: 0.5046Epoch 00004: saving model to model-04.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.6981 - acc: 0.5058 - val_loss: 0.6935 - val_acc: 0.4617\n",
      "Epoch 6/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6946 - acc: 0.4874Epoch 00005: saving model to model-05.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.6946 - acc: 0.4879 - val_loss: 0.6890 - val_acc: 0.4733\n",
      "Epoch 7/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6921 - acc: 0.5029Epoch 00006: saving model to model-06.hdf5\n",
      "120/120 [==============================] - 46s - loss: 0.6921 - acc: 0.5042 - val_loss: 0.6811 - val_acc: 0.4767\n",
      "Epoch 8/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.6206 - acc: 0.6319Epoch 00007: saving model to model-07.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.6187 - acc: 0.6338 - val_loss: 0.5330 - val_acc: 0.7750\n",
      "Epoch 9/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.7912Epoch 00008: saving model to model-08.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.4706 - acc: 0.7929 - val_loss: 0.4176 - val_acc: 0.8300\n",
      "Epoch 10/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.8849Epoch 00009: saving model to model-09.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.3093 - acc: 0.8854 - val_loss: 0.5189 - val_acc: 0.8117\n",
      "Epoch 11/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9227Epoch 00010: saving model to model-10.hdf5\n",
      "120/120 [==============================] - 46s - loss: 0.2341 - acc: 0.9233 - val_loss: 0.4642 - val_acc: 0.8483\n",
      "Epoch 12/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9412Epoch 00011: saving model to model-11.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.1698 - acc: 0.9412 - val_loss: 0.5515 - val_acc: 0.8233\n",
      "Epoch 13/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9702Epoch 00012: saving model to model-12.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.1162 - acc: 0.9704 - val_loss: 0.6427 - val_acc: 0.8383\n",
      "Epoch 14/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9748Epoch 00013: saving model to model-13.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0991 - acc: 0.9746 - val_loss: 0.7045 - val_acc: 0.8133\n",
      "Epoch 15/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9786Epoch 00014: saving model to model-14.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0885 - acc: 0.9783 - val_loss: 0.7115 - val_acc: 0.8267\n",
      "Epoch 16/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9836Epoch 00015: saving model to model-15.hdf5\n",
      "120/120 [==============================] - 46s - loss: 0.0709 - acc: 0.9837 - val_loss: 0.7192 - val_acc: 0.8383\n",
      "Epoch 17/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9870Epoch 00016: saving model to model-16.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0662 - acc: 0.9871 - val_loss: 0.6363 - val_acc: 0.8433\n",
      "Epoch 18/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9824Epoch 00017: saving model to model-17.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0800 - acc: 0.9825 - val_loss: 0.7149 - val_acc: 0.8433\n",
      "Epoch 19/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9891Epoch 00018: saving model to model-18.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0570 - acc: 0.9883 - val_loss: 0.7527 - val_acc: 0.8183\n",
      "Epoch 20/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9874Epoch 00019: saving model to model-19.hdf5\n",
      "120/120 [==============================] - 49s - loss: 0.0558 - acc: 0.9875 - val_loss: 0.7329 - val_acc: 0.8350\n",
      "Epoch 21/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9912Epoch 00020: saving model to model-20.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0438 - acc: 0.9912 - val_loss: 0.9185 - val_acc: 0.8283\n",
      "Epoch 22/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9777Epoch 00021: saving model to model-21.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0795 - acc: 0.9779 - val_loss: 0.6442 - val_acc: 0.8117\n",
      "Epoch 23/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9836Epoch 00022: saving model to model-22.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0566 - acc: 0.9837 - val_loss: 0.8178 - val_acc: 0.8233\n",
      "Epoch 24/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9924Epoch 00023: saving model to model-23.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0404 - acc: 0.9925 - val_loss: 0.7779 - val_acc: 0.8317\n",
      "Epoch 25/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9937Epoch 00024: saving model to model-24.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0348 - acc: 0.9937 - val_loss: 0.8689 - val_acc: 0.8400\n",
      "Epoch 26/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9941Epoch 00025: saving model to model-25.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0320 - acc: 0.9942 - val_loss: 0.9299 - val_acc: 0.8400\n",
      "Epoch 27/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9941Epoch 00026: saving model to model-26.hdf5\n",
      "120/120 [==============================] - 49s - loss: 0.0323 - acc: 0.9942 - val_loss: 0.9620 - val_acc: 0.8433\n",
      "Epoch 28/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9941Epoch 00027: saving model to model-27.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0315 - acc: 0.9942 - val_loss: 1.0094 - val_acc: 0.8417\n",
      "Epoch 29/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9941Epoch 00028: saving model to model-28.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0318 - acc: 0.9942 - val_loss: 1.0216 - val_acc: 0.8450\n",
      "Epoch 30/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9941Epoch 00029: saving model to model-29.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0311 - acc: 0.9942 - val_loss: 1.0538 - val_acc: 0.8433\n",
      "Epoch 31/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9912Epoch 00030: saving model to model-30.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0424 - acc: 0.9912 - val_loss: 0.9365 - val_acc: 0.8417\n",
      "Epoch 32/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9916Epoch 00031: saving model to model-31.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0379 - acc: 0.9917 - val_loss: 0.8819 - val_acc: 0.8450\n",
      "Epoch 33/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9903Epoch 00032: saving model to model-32.hdf5\n",
      "120/120 [==============================] - 49s - loss: 0.0415 - acc: 0.9904 - val_loss: 0.7999 - val_acc: 0.8500\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/120 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9849Epoch 00033: saving model to model-33.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0610 - acc: 0.9850 - val_loss: 0.6509 - val_acc: 0.8400\n",
      "Epoch 35/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9924Epoch 00034: saving model to model-34.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0315 - acc: 0.9925 - val_loss: 0.8575 - val_acc: 0.8467\n",
      "Epoch 36/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9945Epoch 00035: saving model to model-35.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0271 - acc: 0.9946 - val_loss: 0.8924 - val_acc: 0.8433\n",
      "Epoch 37/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9950Epoch 00036: saving model to model-36.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0259 - acc: 0.9950 - val_loss: 0.9897 - val_acc: 0.8417\n",
      "Epoch 38/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9950Epoch 00037: saving model to model-37.hdf5\n",
      "120/120 [==============================] - 49s - loss: 0.0240 - acc: 0.9950 - val_loss: 0.9385 - val_acc: 0.8433\n",
      "Epoch 39/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9954Epoch 00038: saving model to model-38.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0219 - acc: 0.9954 - val_loss: 1.0885 - val_acc: 0.8333\n",
      "Epoch 40/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9954Epoch 00039: saving model to model-39.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0240 - acc: 0.9954 - val_loss: 1.0754 - val_acc: 0.8383\n",
      "Epoch 41/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9958Epoch 00040: saving model to model-40.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0213 - acc: 0.9958 - val_loss: 1.0825 - val_acc: 0.8483\n",
      "Epoch 42/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9958Epoch 00041: saving model to model-41.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0190 - acc: 0.9958 - val_loss: 1.3013 - val_acc: 0.8283\n",
      "Epoch 43/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9962Epoch 00042: saving model to model-42.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0177 - acc: 0.9962 - val_loss: 1.4141 - val_acc: 0.8200\n",
      "Epoch 44/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9908Epoch 00043: saving model to model-43.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0308 - acc: 0.9908 - val_loss: 1.0306 - val_acc: 0.8167\n",
      "Epoch 45/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9941Epoch 00044: saving model to model-44.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0295 - acc: 0.9942 - val_loss: 1.0820 - val_acc: 0.8183\n",
      "Epoch 46/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9954Epoch 00045: saving model to model-45.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0202 - acc: 0.9954 - val_loss: 0.9903 - val_acc: 0.8150\n",
      "Epoch 47/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9962Epoch 00046: saving model to model-46.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0151 - acc: 0.9962 - val_loss: 1.1656 - val_acc: 0.8083\n",
      "Epoch 48/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962Epoch 00047: saving model to model-47.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0149 - acc: 0.9962 - val_loss: 1.2252 - val_acc: 0.8133\n",
      "Epoch 49/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9962Epoch 00048: saving model to model-48.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0133 - acc: 0.9962 - val_loss: 1.2540 - val_acc: 0.8150\n",
      "Epoch 50/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9962Epoch 00049: saving model to model-49.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0108 - acc: 0.9962 - val_loss: 1.2913 - val_acc: 0.8150\n",
      "Epoch 51/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9962Epoch 00050: saving model to model-50.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0088 - acc: 0.9962 - val_loss: 1.3615 - val_acc: 0.8117\n",
      "Epoch 52/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9962Epoch 00051: saving model to model-51.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0077 - acc: 0.9962 - val_loss: 1.3575 - val_acc: 0.8133\n",
      "Epoch 53/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9962Epoch 00052: saving model to model-52.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0071 - acc: 0.9962 - val_loss: 1.4116 - val_acc: 0.8100\n",
      "Epoch 54/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9992Epoch 00053: saving model to model-53.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0034 - acc: 0.9992 - val_loss: 1.4729 - val_acc: 0.8150\n",
      "Epoch 55/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9992Epoch 00054: saving model to model-54.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0044 - acc: 0.9992 - val_loss: 1.5461 - val_acc: 0.8167\n",
      "Epoch 56/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9979Epoch 00055: saving model to model-55.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0068 - acc: 0.9979 - val_loss: 1.5749 - val_acc: 0.8133\n",
      "Epoch 57/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9983Epoch 00056: saving model to model-56.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0109 - acc: 0.9983 - val_loss: 1.5639 - val_acc: 0.8133\n",
      "Epoch 58/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954Epoch 00057: saving model to model-57.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0166 - acc: 0.9950 - val_loss: 1.1292 - val_acc: 0.8183\n",
      "Epoch 59/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9933Epoch 00058: saving model to model-58.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0203 - acc: 0.9933 - val_loss: 1.2664 - val_acc: 0.8300\n",
      "Epoch 60/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9971Epoch 00059: saving model to model-59.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0079 - acc: 0.9971 - val_loss: 1.1196 - val_acc: 0.8233\n",
      "Epoch 61/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996Epoch 00060: saving model to model-60.hdf5\n",
      "120/120 [==============================] - 48s - loss: 0.0012 - acc: 0.9996 - val_loss: 1.2104 - val_acc: 0.8417\n",
      "Epoch 62/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 9.3681e-04 - acc: 1.0000Epoch 00061: saving model to model-61.hdf5\n",
      "120/120 [==============================] - 47s - loss: 9.2958e-04 - acc: 1.0000 - val_loss: 1.3632 - val_acc: 0.8317\n",
      "Epoch 63/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992Epoch 00062: saving model to model-62.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0028 - acc: 0.9992 - val_loss: 1.3897 - val_acc: 0.8217\n",
      "Epoch 64/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9983Epoch 00063: saving model to model-63.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0030 - acc: 0.9983 - val_loss: 1.3568 - val_acc: 0.8233\n",
      "Epoch 65/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 2.0417e-04 - acc: 1.0000Epoch 00064: saving model to model-64.hdf5\n",
      "120/120 [==============================] - 47s - loss: 2.0348e-04 - acc: 1.0000 - val_loss: 1.4079 - val_acc: 0.8250\n",
      "Epoch 66/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.4862e-04 - acc: 1.0000Epoch 00065: saving model to model-65.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 47s - loss: 1.4827e-04 - acc: 1.0000 - val_loss: 1.4482 - val_acc: 0.8233\n",
      "Epoch 67/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 9.4457e-05 - acc: 1.0000Epoch 00066: saving model to model-66.hdf5\n",
      "120/120 [==============================] - 47s - loss: 9.4128e-05 - acc: 1.0000 - val_loss: 1.4799 - val_acc: 0.8233\n",
      "Epoch 68/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 7.1401e-05 - acc: 1.0000Epoch 00067: saving model to model-67.hdf5\n",
      "120/120 [==============================] - 48s - loss: 7.1284e-05 - acc: 1.0000 - val_loss: 1.5085 - val_acc: 0.8217\n",
      "Epoch 69/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 5.7304e-05 - acc: 1.0000Epoch 00068: saving model to model-68.hdf5\n",
      "120/120 [==============================] - 47s - loss: 5.7195e-05 - acc: 1.0000 - val_loss: 1.5339 - val_acc: 0.8217\n",
      "Epoch 70/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 4.8487e-05 - acc: 1.0000Epoch 00069: saving model to model-69.hdf5\n",
      "120/120 [==============================] - 47s - loss: 4.8333e-05 - acc: 1.0000 - val_loss: 1.5568 - val_acc: 0.8217\n",
      "Epoch 71/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 4.0831e-05 - acc: 1.0000Epoch 00070: saving model to model-70.hdf5\n",
      "120/120 [==============================] - 48s - loss: 4.0722e-05 - acc: 1.0000 - val_loss: 1.5781 - val_acc: 0.8233\n",
      "Epoch 72/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 3.7532e-05 - acc: 1.0000Epoch 00071: saving model to model-71.hdf5\n",
      "120/120 [==============================] - 47s - loss: 3.7488e-05 - acc: 1.0000 - val_loss: 1.5995 - val_acc: 0.8250\n",
      "Epoch 73/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 2.8362e-05 - acc: 1.0000Epoch 00072: saving model to model-72.hdf5\n",
      "120/120 [==============================] - 47s - loss: 2.8287e-05 - acc: 1.0000 - val_loss: 1.6171 - val_acc: 0.8250\n",
      "Epoch 74/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 2.6831e-05 - acc: 1.0000Epoch 00073: saving model to model-73.hdf5\n",
      "120/120 [==============================] - 47s - loss: 2.6777e-05 - acc: 1.0000 - val_loss: 1.6342 - val_acc: 0.8250\n",
      "Epoch 75/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 2.5307e-05 - acc: 1.0000Epoch 00074: saving model to model-74.hdf5\n",
      "120/120 [==============================] - 47s - loss: 2.5504e-05 - acc: 1.0000 - val_loss: 1.6521 - val_acc: 0.8250\n",
      "Epoch 76/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 2.1259e-05 - acc: 1.0000Epoch 00075: saving model to model-75.hdf5\n",
      "120/120 [==============================] - 47s - loss: 2.1324e-05 - acc: 1.0000 - val_loss: 1.6682 - val_acc: 0.8250\n",
      "Epoch 77/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.8284e-05 - acc: 1.0000Epoch 00076: saving model to model-76.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.8291e-05 - acc: 1.0000 - val_loss: 1.6832 - val_acc: 0.8233\n",
      "Epoch 78/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.7179e-05 - acc: 1.0000Epoch 00077: saving model to model-77.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.7152e-05 - acc: 1.0000 - val_loss: 1.6978 - val_acc: 0.8233\n",
      "Epoch 79/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.5976e-05 - acc: 1.0000Epoch 00078: saving model to model-78.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.6036e-05 - acc: 1.0000 - val_loss: 1.7119 - val_acc: 0.8233\n",
      "Epoch 80/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.4954e-05 - acc: 1.0000Epoch 00079: saving model to model-79.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.4909e-05 - acc: 1.0000 - val_loss: 1.7267 - val_acc: 0.8233\n",
      "Epoch 81/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.2871e-05 - acc: 1.0000Epoch 00080: saving model to model-80.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.2896e-05 - acc: 1.0000 - val_loss: 1.7399 - val_acc: 0.8250\n",
      "Epoch 82/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.2184e-05 - acc: 1.0000Epoch 00081: saving model to model-81.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.2149e-05 - acc: 1.0000 - val_loss: 1.7535 - val_acc: 0.8250\n",
      "Epoch 83/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.1152e-05 - acc: 1.0000Epoch 00082: saving model to model-82.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.1150e-05 - acc: 1.0000 - val_loss: 1.7663 - val_acc: 0.8250\n",
      "Epoch 84/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 1.0560e-05 - acc: 1.0000Epoch 00083: saving model to model-83.hdf5\n",
      "120/120 [==============================] - 47s - loss: 1.0549e-05 - acc: 1.0000 - val_loss: 1.7798 - val_acc: 0.8250\n",
      "Epoch 85/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 9.1457e-06 - acc: 1.0000Epoch 00084: saving model to model-84.hdf5\n",
      "120/120 [==============================] - 47s - loss: 9.1200e-06 - acc: 1.0000 - val_loss: 1.7916 - val_acc: 0.8250\n",
      "Epoch 86/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 8.6104e-06 - acc: 1.0000Epoch 00085: saving model to model-85.hdf5\n",
      "120/120 [==============================] - 47s - loss: 8.6093e-06 - acc: 1.0000 - val_loss: 1.8034 - val_acc: 0.8250\n",
      "Epoch 87/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 8.3416e-06 - acc: 1.0000Epoch 00086: saving model to model-86.hdf5\n",
      "120/120 [==============================] - 47s - loss: 8.3323e-06 - acc: 1.0000 - val_loss: 1.8164 - val_acc: 0.8250\n",
      "Epoch 88/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 7.7320e-06 - acc: 1.0000Epoch 00087: saving model to model-87.hdf5\n",
      "120/120 [==============================] - 47s - loss: 7.7284e-06 - acc: 1.0000 - val_loss: 1.8278 - val_acc: 0.8250\n",
      "Epoch 89/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 7.0894e-06 - acc: 1.0000Epoch 00088: saving model to model-88.hdf5\n",
      "120/120 [==============================] - 47s - loss: 7.0767e-06 - acc: 1.0000 - val_loss: 1.8407 - val_acc: 0.8233\n",
      "Epoch 90/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 6.7020e-06 - acc: 1.0000Epoch 00089: saving model to model-89.hdf5\n",
      "120/120 [==============================] - 47s - loss: 6.6931e-06 - acc: 1.0000 - val_loss: 1.8524 - val_acc: 0.8233\n",
      "Epoch 91/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 6.2749e-06 - acc: 1.0000Epoch 00090: saving model to model-90.hdf5\n",
      "120/120 [==============================] - 47s - loss: 6.2629e-06 - acc: 1.0000 - val_loss: 1.8650 - val_acc: 0.8233\n",
      "Epoch 92/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 5.9316e-06 - acc: 1.0000Epoch 00091: saving model to model-91.hdf5\n",
      "120/120 [==============================] - 48s - loss: 5.9263e-06 - acc: 1.0000 - val_loss: 1.8777 - val_acc: 0.8233\n",
      "Epoch 93/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 5.3356e-06 - acc: 1.0000Epoch 00092: saving model to model-92.hdf5\n",
      "120/120 [==============================] - 47s - loss: 5.3359e-06 - acc: 1.0000 - val_loss: 1.8884 - val_acc: 0.8233\n",
      "Epoch 94/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 5.2243e-06 - acc: 1.0000Epoch 00093: saving model to model-93.hdf5\n",
      "120/120 [==============================] - 47s - loss: 5.2408e-06 - acc: 1.0000 - val_loss: 1.9026 - val_acc: 0.8250\n",
      "Epoch 95/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 4.4054e-06 - acc: 1.0000Epoch 00094: saving model to model-94.hdf5\n",
      "120/120 [==============================] - 47s - loss: 4.3979e-06 - acc: 1.0000 - val_loss: 1.9123 - val_acc: 0.8250\n",
      "Epoch 96/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9916Epoch 00095: saving model to model-95.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0360 - acc: 0.9917 - val_loss: 0.8198 - val_acc: 0.8183\n",
      "Epoch 97/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9954Epoch 00096: saving model to model-96.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0190 - acc: 0.9954 - val_loss: 1.4947 - val_acc: 0.7817\n",
      "Epoch 98/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9966Epoch 00097: saving model to model-97.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 47s - loss: 0.0156 - acc: 0.9967 - val_loss: 1.1038 - val_acc: 0.8183\n",
      "Epoch 99/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9971Epoch 00098: saving model to model-98.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0145 - acc: 0.9971 - val_loss: 1.0789 - val_acc: 0.8133\n",
      "Epoch 100/100\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9992Epoch 00099: saving model to model-99.hdf5\n",
      "120/120 [==============================] - 47s - loss: 0.0056 - acc: 0.9992 - val_loss: 1.0268 - val_acc: 0.8217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1650b409dd8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "num_epochs = 100\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "checkpointer = ModelCheckpoint(filepath='model-{epoch:02d}.hdf5', verbose=1)\n",
    "model.fit_generator(train.batch(), len(train_data)//20, num_epochs, validation_data = valid.batch(),\n",
    "                    validation_steps = len(valid_data)//20, callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Trained model\n",
    "The following section Loads the trained model and lets you predict the sentiment of your sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "f = open(\"important_data.obj\", \"rb\")\n",
    "vocab, word_to_index, useful_emb = pickle.load(f)\n",
    "f.close()\n",
    "m = load_model(r\"model-99.hdf5\")\n",
    "translation = str.maketrans(\"\",\"\", string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 0 to stop else Enter 1: 1\n",
      "Enter your sentence: I don't like this.\n",
      "Sentiment: Negative\n",
      "Enter 0 to stop else Enter 1: 1\n",
      "Enter your sentence: Just love it, EXCELLENT MOVIE!!!\n",
      "Sentiment: Positive\n",
      "Enter 0 to stop else Enter 1: 1\n",
      "Enter your sentence: Shit movie.\n",
      "Sentiment: Negative\n",
      "Enter 0 to stop else Enter 1: 1\n",
      "Enter your sentence: I don't recommend it to anyone at all.\n",
      "Sentiment: Negative\n",
      "Enter 0 to stop else Enter 1: 1\n",
      "Enter your sentence: EXCELLENT BUY!!!\n",
      "Sentiment: Positive\n",
      "Enter 0 to stop else Enter 1: 0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    choice = int(input(\"Enter 0 to stop else Enter 1: \"))\n",
    "    if choice == 0:\n",
    "        break\n",
    "    sent = input(\"Enter your sentence: \")\n",
    "    sent = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-])\\s*\", r\"\\1 \", sent).lower()\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('/', ' ')\n",
    "    sent = sent.translate(translation)\n",
    "    sent = sent.split()\n",
    "    for i, word in enumerate(sent):\n",
    "        if(word not in vocab):\n",
    "            sent[i] = \"unk\"\n",
    "\n",
    "    index_sent = []\n",
    "    for word in sent:\n",
    "        index_sent.append(word_to_index[word])\n",
    "    index_sent.append(word_to_index['eos'])\n",
    "    index_sent = np.reshape(index_sent, (1, len(index_sent)))\n",
    "    prediction = m.predict(index_sent)\n",
    "    if prediction[0][0] >= 0.5:\n",
    "        print(\"Sentiment: Positive\")\n",
    "    else:\n",
    "        print(\"Sentiment: Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
